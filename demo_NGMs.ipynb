
{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling Gaussian Graphical models\n",
        "\n",
        "We design a synthetic experiment to study the capability of NGMs to represent Gaussian graphical models. The input data X is sampled from a multivariate Gaussian distribution where we define the underlying precision matrix. The graph input G to the NGM will be the corresponding partial correlation matrix. We know that every conditional distribution of a multivariate Gaussian distribution is a Gaussian distribution. The aim of this experiment is to see (via plots) how close are the distributions learned by the NGMs. We additionally gauge the sampling ability of NGMs to model the multivariate Gaussian distribution."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "# reloads modules automatically before entering the \n",
        "# execution of code typed at the IPython prompt.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "print(sys.prefix)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pickle"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n/anaconda/envs/ngm\n"
        }
      ],
      "execution_count": 102,
      "metadata": {
        "gather": {
          "logged": 1674631887137
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup the Gaussian graphical model\n",
        "1. Initialize a graph type.\n",
        "2. Get the precision matrix `theta` and corresponding samples `X` from a multivariate Gaussian distribution.\n",
        "3. Get the partial correlations matrix `rho` and the graph `G`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Local imports\n",
        "from ngm.utils import ggm\n",
        "from ngm.utils import data_processing as dp\n",
        "# from uGLAD.utils.metrics import reportMetrics\n",
        "\n",
        "# Xb = samples batch, trueTheta = corresponding true precision matrices\n",
        "Xb, true_theta = ggm.get_data(\n",
        "    num_nodes=10, \n",
        "    typeG='CHAIN', \n",
        "    sparsity=[0.2, 0.2], # Not used for chain graph\n",
        "    num_samples=5000, \n",
        "    batch_size=1,\n",
        "    eig_offset=0.1, \n",
        "    w_min=0.5,\n",
        "    w_max=1\n",
        ")\n",
        "X, true_theta =Xb[0], true_theta[0]\n",
        "# set the column names for X\n",
        "X = pd.DataFrame(X, columns=['n'+str(i) for i in range(X.shape[1])])\n",
        "rho = ggm.get_partial_correlations(true_theta)\n",
        "print(f'partial correlations: {rho.shape}, Samples {X.shape}')\n",
        "G, image_G, graph_edge_list = ggm.graph_from_partial_correlations(rho, X.columns)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "partial correlations: (10, 10), Samples (5000, 10)\nSparsity 1 using threshold 0.0\n"
        }
      ],
      "execution_count": 103,
      "metadata": {
        "gather": {
          "logged": 1674631891270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gv = dp.get_interactive_graph(G, 'GGM Chain graph', node_PREFIX=None)\n",
        "Gv.show('viz_ggm.html')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 104,
          "data": {
            "text/plain": "<IPython.lib.display.IFrame at 0x7f3f998e7a00>",
            "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"750px\"\n            src=\"viz_ggm.html\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
          },
          "metadata": {}
        }
      ],
      "execution_count": 104,
      "metadata": {
        "gather": {
          "logged": 1674631893247
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NGM: Learning\n",
        "\n",
        "For faster runtimes, set USE_CUDA=True"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# import ngm.learning as ngm_learn\n",
        "import ngm.main as ngm\n",
        "\n",
        "# Learning the NMG model\n",
        "model_NGM = ngm.learning(\n",
        "    G, X, lambd=1e0,\n",
        "    hidden_dim=50,\n",
        "    epochs=2000, \n",
        "    lr=0.001,\n",
        "    norm_type='min_max',\n",
        "    k_fold=1,\n",
        "    structure_penalty='hadamard'\n",
        ") "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Means of selected features (n0   -0.009119\nn1    0.003523\nn2    0.014093\nn3    0.018689\nn4   -0.001911\nn5    0.001762\nn6    0.004760\nn7   -0.004932\nn8   -0.003290\nn9   -0.004423\ndtype: float64, 10)\nNormalizing the data: min_max\n: Processing the input table for basic compatibility check\n: The input table has sample 5000 and features 10\n: Total zero samples dropped 0\n: Single value columns dropped: total 0, columns []\n: Duplicates dropped: total 0, columns []\n: The processed table has sample 5000 and features 10\n: Total time to process the table 0.735 secs\nFold num 0\nInitializing the NGM model\n\nFold 0: epoch:0/2000\nTrain: loss=-3.402433156967163, reg=0.2502201497554779, struct=-3.652653217315674\nTest: loss=-3.40280818939209, reg=0.24984467029571533, struct=-3.6526529788970947\n\nFold 0: epoch:200/2000\nTrain: loss=-4.31679105758667, reg=0.012574750930070877, struct=-4.3293657302856445\nTest: loss=-4.316832065582275, reg=0.012533806264400482, struct=-4.3293657302856445\n\nFold 0: epoch:400/2000\nTrain: loss=-5.819553375244141, reg=0.013269470073282719, struct=-5.832822799682617\nTest: loss=-5.819529056549072, reg=0.013293764553964138, struct=-5.832822799682617\n\nFold 0: epoch:600/2000\nTrain: loss=-8.977989196777344, reg=0.01539037749171257, struct=-8.993379592895508\nTest: loss=-8.977935791015625, reg=0.015443823300302029, struct=-8.993379592895508\n\nFold 0: epoch:800/2000\nTrain: loss=-9.735547065734863, reg=0.015021681785583496, struct=-9.750568389892578\nTest: loss=-9.735437393188477, reg=0.015130982734262943, struct=-9.750568389892578\n\nFold 0: epoch:1000/2000\nTrain: loss=-9.936190605163574, reg=0.015841124579310417, struct=-9.952032089233398\nTest: loss=-9.93623161315918, reg=0.01580112613737583, struct=-9.952033042907715\n\nFold 0: epoch:1200/2000\nTrain: loss=-10.298130989074707, reg=0.01442759484052658, struct=-10.3125581741333\nTest: loss=-10.298055648803711, reg=0.014502119272947311, struct=-10.3125581741333\n\nFold 0: epoch:1400/2000\nTrain: loss=-10.466117858886719, reg=0.014995395205914974, struct=-10.48111343383789\nTest: loss=-10.46631145477295, reg=0.014801796525716782, struct=-10.48111343383789\n\nFold 0: epoch:1600/2000\nTrain: loss=-10.463096618652344, reg=0.014311760663986206, struct=-10.477408409118652\nTest: loss=-10.462995529174805, reg=0.01441264059394598, struct=-10.477408409118652\n\nFold 0: epoch:1800/2000\nTrain: loss=-10.550418853759766, reg=0.013654345646500587, struct=-10.56407356262207\nTest: loss=-10.55035400390625, reg=0.013719202019274235, struct=-10.56407356262207\n\n\nBest model selected: Fold 0: epoch:1953/2000:\n                    Train: loss=-10.771074295043945, reg=0.013734741136431694, struct=-10.784809112548828\n                    Test: loss=-10.77112102508545, reg=0.013688049279153347, struct=-10.784809112548828\n"
        }
      ],
      "execution_count": 105,
      "metadata": {
        "gather": {
          "logged": 1674631901138
        }
      }
    },
    {
      "cell_type": "markdown",